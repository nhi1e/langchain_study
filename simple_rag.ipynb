{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7ce2c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "\n",
    "load_dotenv()\n",
    "if \"OPENAI_API_KEY\" not in os.environ:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")\n",
    "if \"LANGCHAIN_API_KEY\" not in os.environ:\n",
    "    os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass(\"Enter your LangChain API key: \")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145500f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 1 document with length 43047\n",
      "\n",
      "\n",
      "      LLM Powered Autonomous Agents\n",
      "    \n",
      "Date: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\n",
      "\n",
      "\n",
      "Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\n",
      "Agent System Overview#\n",
      "In\n"
     ]
    }
   ],
   "source": [
    "# 1: Load: load data with document loaders (using WebBaseLoader which uses BeutifulSoup)\n",
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "# only get relevant HTML elements\n",
    "bs4_strainer = bs4.SoupStrainer(class_=(\"post-title\", \"post-header\", \"post-content\"))\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs={\"parse_only\": bs4_strainer}, # only load specific HTML elements\n",
    ")\n",
    "\n",
    "# load the data\n",
    "docs = loader.load()\n",
    "\n",
    "print(\"loaded\", len(docs), \"document with length\", len(docs[0].page_content))  # check the number of documents and number of characters in the first document\n",
    "print(docs[0].page_content[:500])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9120960a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split into 63 chunks with length 969\n",
      "{'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 34990}\n"
     ]
    }
   ],
   "source": [
    "# 2: Split: split documents into smaller chunks \n",
    "#           smaller chunks can fit into context window and easier to search over and pass to LLM\n",
    "#            also for embedding and vector store\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,        # size of each chunk\n",
    "    chunk_overlap=200,      # overlap between chunks (to preserve context in case some information is split across chunks)\n",
    "    add_start_index=True,   # store start index to each chunk\n",
    ")\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "print(\"split into\", len(all_splits), \"chunks with length\", len(all_splits[0].page_content))  # check the number of chunks and number of characters in the first chunk\n",
    "print(all_splits[50].metadata)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912c5e74",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88534ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7ba4b3c8",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
