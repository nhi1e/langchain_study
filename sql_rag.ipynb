{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b36b5b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --upgrade --quiet langchain langchain-community langchain-openai faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fdab6060",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\" \n",
    "\n",
    "load_dotenv()\n",
    "if \"OPENAI_API_KEY\" not in os.environ:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")\n",
    "if \"LANGCHAIN_API_KEY\" not in os.environ:\n",
    "    os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass(\"Enter your LangChain API key: \")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f7875e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities import SQLDatabase\n",
    "\n",
    "db = SQLDatabase.from_uri(\"sqlite:///Chinook.db\") # select relative database file\n",
    "\n",
    "# print(db.dialect)\n",
    "# print(db.get_usable_table_names())\n",
    "# db.run(\"SELECT * FROM Artist LIMIT 10;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b32a672a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "\n",
    "#schema for the final dictionary and pipeline\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    query: str\n",
    "    result: str\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6eef038c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "\n",
      "Given an input question, create a syntactically correct \u001b[33;1m\u001b[1;3m{dialect}\u001b[0m query to\n",
      "run to help find the answer. Unless the user specifies in his question a\n",
      "specific number of examples they wish to obtain, always limit your query to\n",
      "at most \u001b[33;1m\u001b[1;3m{top_k}\u001b[0m results. You can order the results by a relevant column to\n",
      "return the most interesting examples in the database.\n",
      "\n",
      "Never query for all the columns from a specific table, only ask for a the\n",
      "few relevant columns given the question.\n",
      "\n",
      "Pay attention to use only the column names that you can see in the schema\n",
      "description. Be careful to not query for columns that do not exist. Also,\n",
      "pay attention to which column is in which table.\n",
      "\n",
      "Only use the following tables:\n",
      "\u001b[33;1m\u001b[1;3m{table_info}\u001b[0m\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Question: \u001b[33;1m\u001b[1;3m{input}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_message = \"\"\"\n",
    "Given an input question, create a syntactically correct {dialect} query to\n",
    "run to help find the answer. Unless the user specifies in his question a\n",
    "specific number of examples they wish to obtain, always limit your query to\n",
    "at most {top_k} results. You can order the results by a relevant column to\n",
    "return the most interesting examples in the database.\n",
    "\n",
    "Never query for all the columns from a specific table, only ask for a the\n",
    "few relevant columns given the question.\n",
    "\n",
    "Pay attention to use only the column names that you can see in the schema\n",
    "description. Be careful to not query for columns that do not exist. Also,\n",
    "pay attention to which column is in which table.\n",
    "\n",
    "Only use the following tables:\n",
    "{table_info}\n",
    "\"\"\"\n",
    "\n",
    "user_prompt = \"Question: {input}\" \n",
    "\n",
    "query_prompt_template = ChatPromptTemplate(\n",
    "    [(\"system\", system_message),\n",
    "    (\"human\", user_prompt)],\n",
    ")\n",
    "\n",
    "for message in query_prompt_template.messages:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6bdc98f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'SELECT COUNT(*) AS TrackCount FROM Track;'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert prompt to query using llm itself\n",
    "from typing_extensions import Annotated\n",
    "\n",
    "class QueryState(TypedDict):\n",
    "    query: Annotated[str, ..., \"A syntactically correct SQL query to run.\"] \n",
    "    # define the structure of the llm output to be a dictionary with a query string (so we dont get extra text like \"The query is: ...\")\n",
    "\n",
    "# populate parameters for the query prompt\n",
    "def write_query(state: State):\n",
    "    # Fill in the template with a dict, not kwargs\n",
    "    prompt = query_prompt_template.invoke({\n",
    "        \"dialect\": db.dialect,\n",
    "        \"top_k\": 10,\n",
    "        \"table_info\": db.get_table_info(),\n",
    "        \"input\": state[\"question\"],\n",
    "    })\n",
    "    structured_llm = llm.with_structured_output(QueryState)  # use the llm with structured output\n",
    "    result = structured_llm.invoke(prompt)\n",
    "    return result\n",
    "\n",
    "write_query({\"question\": \"How many tracks are there in the database?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ff4c36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'result': '[(3503,)]'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. execute the query: excexute the generated sql query\n",
    "from langchain_community.tools.sql_database.tool import QuerySQLDataBaseTool\n",
    "\n",
    "def execute_query(state: State):\n",
    "    execute_query_tool = QuerySQLDataBaseTool(db=db)            \n",
    "    return {\"result\": execute_query_tool.invoke(state[\"query\"])} # use the QuerySQLDataBaseTool to execute the query\n",
    "\n",
    "execute_query({'query': 'SELECT COUNT(*) as TotalTracks FROM Track;'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9699e4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. generate answer from the result\n",
    "def generate_answer(state: State):\n",
    "    prompt = (\n",
    "        \"Given the following user question, corresponding SQL query, \"\n",
    "        \"and SQL result, answer the user question.\\n\\n\"\n",
    "        f'Question: {state[\"question\"]}\\n'\n",
    "        f'SQL Query: {state[\"query\"]}\\n'\n",
    "        f'SQL Result: {state[\"result\"]}'\n",
    "    )\n",
    "    response = llm.invoke(prompt)\n",
    "    return {\"answer\": response.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37339192",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, StateGraph\n",
    "# build the pipeline using LangGraph\n",
    "graph_builder = StateGraph(State).add_sequence(\n",
    "    [write_query, execute_query, generate_answer]\n",
    ")\n",
    "# add entry point to tell graph where to start\n",
    "graph_builder.add_edge(START, \"write_query\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabb9032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "config:\n",
      "  flowchart:\n",
      "    curve: linear\n",
      "---\n",
      "graph TD;\n",
      "\t__start__([<p>__start__</p>]):::first\n",
      "\twrite_query(write_query)\n",
      "\texecute_query(execute_query)\n",
      "\tgenerate_answer(generate_answer)\n",
      "\t__end__([<p>__end__</p>]):::last\n",
      "\t__start__ --> write_query;\n",
      "\texecute_query --> generate_answer;\n",
      "\twrite_query --> execute_query;\n",
      "\tgenerate_answer --> __end__;\n",
      "\tclassDef default fill:#f2f0ff,line-height:1.2\n",
      "\tclassDef first fill-opacity:0\n",
      "\tclassDef last fill:#bfb6fc\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "from langchain_core.runnables.graph import CurveStyle, MermaidDrawMethod, NodeStyles\n",
    "\n",
    "print(graph.get_graph().draw_mermaid()) # text representation of the graph\n",
    "try:\n",
    "    with open(\"sql_graph.mmd\", \"w\") as f:\n",
    "        f.write(graph.get_graph().draw_mermaid())  \n",
    "        # i cant display the graph in this notebook, so saving it to a file\n",
    "        # mmdc -i sql_graph.mmd -o sql_graph.png\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0d44f53f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'write_query': {'query': 'SELECT COUNT(*) AS EmployeeCount FROM Employee;'}}\n",
      "{'execute_query': {'result': '[(8,)]'}}\n",
      "{'generate_answer': {'answer': 'There are 8 employees.'}}\n"
     ]
    }
   ],
   "source": [
    "for step in graph.stream(\n",
    "    {\"question\": \"How many employees are there?\"}, stream_mode=\"updates\"\n",
    "):\n",
    "    print(step)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
